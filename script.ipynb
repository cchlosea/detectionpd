{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved N_01.jpg with classification not real\n",
      "Saved N_02.jpg with classification not real\n",
      "Saved N_03.jpg with classification not real\n",
      "Saved N_04.jpg with classification not real\n",
      "Saved N_05.jpg with classification not real\n",
      "Saved N_06.jpg with classification not real\n",
      "Saved N_07.jpg with classification not real\n",
      "Saved N_08.jpg with classification not real\n",
      "Saved N_09.jpg with classification not real\n",
      "Saved N_10.jpg with classification not real\n",
      "Saved N_11.jpg with classification not real\n",
      "Saved N_12.jpg with classification not real\n",
      "Saved N_13.jpg with classification not real\n",
      "Saved N_14.jpg with classification not real\n",
      "Saved N_15.jpg with classification not real\n",
      "Saved N_16.jpg with classification not real\n",
      "Saved N_17.jpg with classification not real\n",
      "Saved N_18.jpg with classification not real\n",
      "Saved N_19.jpg with classification not real\n",
      "Saved N_20.jpg with classification not real\n",
      "Saved N_21.jpg with classification not real\n",
      "Saved N_22.jpg with classification not real\n",
      "Saved N_23.jpg with classification not real\n",
      "Saved N_24.jpg with classification not real\n",
      "Saved N_25.jpg with classification not real\n",
      "Saved P_01.jpg with classification real\n",
      "Saved P_02.jpg with classification real\n",
      "Saved P_03.jpg with classification real\n",
      "Saved P_04.jpg with classification real\n",
      "Saved P_05.jpg with classification real\n",
      "Saved P_06.jpg with classification real\n",
      "Saved P_07.jpg with classification real\n",
      "Saved P_08.jpg with classification real\n",
      "Saved P_09.jpg with classification real\n",
      "Saved P_10.jpg with classification real\n",
      "Saved P_11.jpg with classification real\n",
      "Saved P_12.jpg with classification real\n",
      "Saved P_13.jpg with classification real\n",
      "Saved P_14.jpg with classification real\n",
      "Saved P_15.jpg with classification real\n",
      "Saved P_16.jpg with classification real\n",
      "Saved P_17.jpg with classification real\n",
      "Saved P_18.jpg with classification real\n",
      "Saved P_19.jpg with classification real\n",
      "Saved P_20.jpg with classification real\n",
      "Saved P_21.jpg with classification real\n",
      "Saved P_22.jpg with classification real\n",
      "Saved P_23.jpg with classification real\n",
      "Saved P_24.jpg with classification real\n",
      "Saved P_25.jpg with classification real\n",
      "TP: 23, TN: 16, FP: 9, FN: 2\n",
      "Accuracy: 78.00%\n",
      "Confusion Matrix for Faces:\n",
      " [[18  0]\n",
      " [ 0 32]]\n",
      "Classification Report for Faces:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        18\n",
      "           1       1.00      1.00      1.00        32\n",
      "\n",
      "    accuracy                           1.00        50\n",
      "   macro avg       1.00      1.00      1.00        50\n",
      "weighted avg       1.00      1.00      1.00        50\n",
      "\n",
      "Confusion Matrix for Objects:\n",
      " [[ 0  0]\n",
      " [ 6 28]]\n",
      "Classification Report for Objects:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.82      0.90        34\n",
      "\n",
      "    accuracy                           0.82        34\n",
      "   macro avg       0.50      0.41      0.45        34\n",
      "weighted avg       1.00      0.82      0.90        34\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\seahc\\anaconda3\\envs\\cve\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\seahc\\anaconda3\\envs\\cve\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\seahc\\anaconda3\\envs\\cve\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1509: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# Paths\n",
    "input_path = r'data'\n",
    "output_path = r'result\\data_result'\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Classifiers\n",
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "object_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')  # General object detection on face\n",
    "\n",
    "# Function to classify based on filename\n",
    "def classify_face(filename):\n",
    "    return 'real' if filename.startswith('P') else 'not real'\n",
    "\n",
    "# Function for Non-Maximum Suppression (NMS)\n",
    "def non_max_suppression(boxes, overlapThresh):\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    boxes = np.array(boxes)\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "    \n",
    "    pick = []\n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    x2 = boxes[:,2] + boxes[:,0]\n",
    "    y2 = boxes[:,3] + boxes[:,1]\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(y2)\n",
    "\n",
    "    while len(idxs) > 0:\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "        idxs = np.delete(idxs, np.concatenate(([last], np.where(overlap > overlapThresh)[0])))\n",
    "\n",
    "    return boxes[pick].astype(\"int\")\n",
    "\n",
    "# Initialize metrics\n",
    "TP = TN = FP = FN = 0\n",
    "y_true_faces = []\n",
    "y_pred_faces = []\n",
    "y_true_objects = []\n",
    "y_pred_objects = []\n",
    "\n",
    "# Process each image\n",
    "for filename in os.listdir(input_path):\n",
    "    if filename.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "        img = cv2.imread(os.path.join(input_path, filename))\n",
    "        \n",
    "        # Convert to grayscale and apply CLAHE to each color channel\n",
    "        channels = cv2.split(img)\n",
    "        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "        clahe_channels = [clahe.apply(channel) for channel in channels]\n",
    "        clahe_image = cv2.merge(clahe_channels)\n",
    "        \n",
    "        gray_image = cv2.cvtColor(clahe_image, cv2.COLOR_BGR2GRAY)\n",
    "        gray_image = cv2.GaussianBlur(gray_image, (3, 3), 0)  # Reduced blur for sharper edges\n",
    "        \n",
    "        # Face detection with refined parameters\n",
    "        faces = face_cascade.detectMultiScale(\n",
    "            gray_image, scaleFactor=1.03, minNeighbors=8, minSize=(30, 30)\n",
    "        )\n",
    "        faces = non_max_suppression(faces, 0.3)\n",
    "        classification = classify_face(filename)\n",
    "        \n",
    "        if len(faces) == 0:\n",
    "            TN += (classification == 'not real')\n",
    "            FN += (classification == 'real')\n",
    "            y_true_faces.append(0)  # 0 = not real\n",
    "            y_pred_faces.append(0)\n",
    "        else:\n",
    "            for (x, y, w, h) in faces:\n",
    "                cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 0), 2)\n",
    "                cv2.putText(img, classification, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 0), 2)\n",
    "                \n",
    "            TP += (classification == 'real')\n",
    "            FP += (classification == 'not real')\n",
    "            y_true_faces.append(1)  # 1 = real\n",
    "            y_pred_faces.append(1)\n",
    "            \n",
    "            # Restrict object detection to the face region\n",
    "            for (x, y, w, h) in faces:\n",
    "                face_region = gray_image[y:y+h, x:x+w]  # Crop the face region from the grayscale image\n",
    "                objects = object_cascade.detectMultiScale(\n",
    "                    face_region, scaleFactor=1.03, minNeighbors=6, minSize=(15, 15)\n",
    "                )\n",
    "                objects = non_max_suppression(objects, 0.3)\n",
    "                \n",
    "                y_true_objects.append(1)  # Assume objects are present if detected\n",
    "                \n",
    "                if len(objects) > 0:\n",
    "                    y_pred_objects.append(1)\n",
    "                    for (ox, oy, ow, oh) in objects:\n",
    "                        cv2.rectangle(img, (x+ox, y+oy), (x+ox+ow, y+oy+oh), (255, 255, 0), 2)\n",
    "                        cv2.putText(img, 'Object', (x+ox, y+oy-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 0), 2)\n",
    "                else:\n",
    "                    y_pred_objects.append(0)\n",
    "        \n",
    "        # Save the processed image\n",
    "        cv2.imwrite(os.path.join(output_path, filename), img)\n",
    "        print(f'Saved {filename} with classification {classification}')\n",
    "\n",
    "# Calculate performance metrics\n",
    "total_images = TP + TN + FP + FN\n",
    "print(f\"TP: {TP}, TN: {TN}, FP: {FP}, FN: {FN}\")\n",
    "print(f\"Accuracy: {(TP + TN) / total_images * 100:.2f}%\")\n",
    "\n",
    "# Confusion Matrix and Classification Report for Face Detection\n",
    "conf_matrix_faces = confusion_matrix(y_true_faces, y_pred_faces)\n",
    "print(\"Confusion Matrix for Faces:\\n\", conf_matrix_faces)\n",
    "print(\"Classification Report for Faces:\\n\", classification_report(y_true_faces, y_pred_faces))\n",
    "\n",
    "# Confusion Matrix and Classification Report for Object Detection\n",
    "conf_matrix_objects = confusion_matrix(y_true_objects, y_pred_objects)\n",
    "print(\"Confusion Matrix for Objects:\\n\", conf_matrix_objects)\n",
    "print(\"Classification Report for Objects:\\n\", classification_report(y_true_objects, y_pred_objects))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
