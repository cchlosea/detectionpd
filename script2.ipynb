{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved N_01.jpg with classification not real\n",
      "Saved N_02.jpg with classification not real\n",
      "Saved N_03.jpg with classification not real\n",
      "Saved N_04.jpg with classification not real\n",
      "Saved N_05.jpg with classification not real\n",
      "Saved N_06.jpg with classification not real\n",
      "Saved N_07.jpg with classification not real\n",
      "Saved N_08.jpg with classification not real\n",
      "Saved N_09.jpg with classification not real\n",
      "Saved N_10.jpg with classification not real\n",
      "Saved N_11.jpg with classification not real\n",
      "Saved N_12.jpg with classification not real\n",
      "Saved N_13.jpg with classification not real\n",
      "Saved N_14.jpg with classification not real\n",
      "Saved N_15.jpg with classification not real\n",
      "Saved N_16.jpg with classification not real\n",
      "Saved N_17.jpg with classification not real\n",
      "Saved N_18.jpg with classification not real\n",
      "Saved N_19.jpg with classification not real\n",
      "Saved N_20.jpg with classification not real\n",
      "Saved N_21.jpg with classification not real\n",
      "Saved N_22.jpg with classification not real\n",
      "Saved N_23.jpg with classification not real\n",
      "Saved N_24.jpg with classification not real\n",
      "Saved N_25.jpg with classification not real\n",
      "Saved P_01.jpg with classification real\n",
      "Saved P_02.jpg with classification real\n",
      "Saved P_03.jpg with classification real\n",
      "Saved P_04.jpg with classification real\n",
      "Saved P_05.jpg with classification real\n",
      "Saved P_06.jpg with classification real\n",
      "Saved P_07.jpg with classification real\n",
      "Saved P_08.jpg with classification real\n",
      "Saved P_09.jpg with classification real\n",
      "Saved P_10.jpg with classification real\n",
      "Saved P_11.jpg with classification real\n",
      "Saved P_12.jpg with classification real\n",
      "Saved P_13.jpg with classification real\n",
      "Saved P_14.jpg with classification real\n",
      "Saved P_15.jpg with classification real\n",
      "Saved P_16.jpg with classification real\n",
      "Saved P_17.jpg with classification real\n",
      "Saved P_18.jpg with classification real\n",
      "Saved P_19.jpg with classification real\n",
      "Saved P_20.jpg with classification real\n",
      "Saved P_21.jpg with classification real\n",
      "Saved P_22.jpg with classification real\n",
      "Saved P_23.jpg with classification real\n",
      "Saved P_24.jpg with classification real\n",
      "Saved P_25.jpg with classification real\n",
      "Length of y_true_faces: 50\n",
      "Length of y_pred_faces: 50\n",
      "Length of y_true_objects: 50\n",
      "Length of y_pred_objects: 50\n",
      "TP: 25, TN: 6, FP: 19, FN: 0\n",
      "Accuracy: 62.00%\n",
      "Confusion Matrix for Faces:\n",
      " [[ 6  0]\n",
      " [ 0 44]]\n",
      "Classification Report for Faces:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         6\n",
      "           1       1.00      1.00      1.00        44\n",
      "\n",
      "    accuracy                           1.00        50\n",
      "   macro avg       1.00      1.00      1.00        50\n",
      "weighted avg       1.00      1.00      1.00        50\n",
      "\n",
      "Confusion Matrix for Objects:\n",
      " [[18  7]\n",
      " [ 2 23]]\n",
      "Classification Report for Objects:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.72      0.80        25\n",
      "           1       0.77      0.92      0.84        25\n",
      "\n",
      "    accuracy                           0.82        50\n",
      "   macro avg       0.83      0.82      0.82        50\n",
      "weighted avg       0.83      0.82      0.82        50\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from cv2.dnn import readNet, blobFromImage, NMSBoxes, readNetFromCaffe\n",
    "\n",
    "# Paths\n",
    "input_path = r'data'\n",
    "output_path = r'resuult\\data_result'\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Load YOLOv3 model and configuration\n",
    "net = readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "layer_names = net.getLayerNames()\n",
    "output_layers = [layer_names[i - 1] for i in net.getUnconnectedOutLayers()]\n",
    "with open(\"coco.names\", \"r\") as f:\n",
    "    classes = [line.strip() for line in f.readlines()]\n",
    "\n",
    "# Data Augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Function to classify based on filename\n",
    "def classify_face(filename):\n",
    "    return 'real' if filename.startswith('P') else 'not real'\n",
    "\n",
    "# Function for Non-Maximum Suppression (NMS)\n",
    "def non_max_suppression(boxes, overlapThresh):\n",
    "    if len(boxes) == 0:\n",
    "        return []\n",
    "\n",
    "    boxes = np.array(boxes)\n",
    "    if boxes.dtype.kind == \"i\":\n",
    "        boxes = boxes.astype(\"float\")\n",
    "    \n",
    "    pick = []\n",
    "    x1 = boxes[:,0]\n",
    "    y1 = boxes[:,1]\n",
    "    x2 = boxes[:,2] + boxes[:,0]\n",
    "    y2 = boxes[:,3] + boxes[:,1]\n",
    "    area = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
    "    idxs = np.argsort(y2)\n",
    "\n",
    "    while len(idxs) > 0:\n",
    "        last = len(idxs) - 1\n",
    "        i = idxs[last]\n",
    "        pick.append(i)\n",
    "\n",
    "        xx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
    "        yy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
    "        xx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
    "        yy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
    "\n",
    "        w = np.maximum(0, xx2 - xx1 + 1)\n",
    "        h = np.maximum(0, yy2 - yy1 + 1)\n",
    "\n",
    "        overlap = (w * h) / area[idxs[:last]]\n",
    "        idxs = np.delete(idxs, np.concatenate(([last], np.where(overlap > overlapThresh)[0])))\n",
    "\n",
    "    return boxes[pick].astype(\"int\")\n",
    "\n",
    "# Initialize metrics\n",
    "TP = TN = FP = FN = 0\n",
    "y_true_faces = []\n",
    "y_pred_faces = []\n",
    "y_true_objects = []\n",
    "y_pred_objects = []\n",
    "\n",
    "# Load face detection model\n",
    "prototxt_path = \"deploy.prototxt\"  # Update with your path if needed\n",
    "caffemodel_path = \"res10_300x300_ssd_iter_140000_fp16.caffemodel\"  # Update with your path if needed\n",
    "face_net = readNetFromCaffe(prototxt_path, caffemodel_path)\n",
    "\n",
    "# Process each image\n",
    "for filename in os.listdir(input_path):\n",
    "    if filename.endswith(('.png', '.jpg', '.jpeg', '.bmp', '.gif')):\n",
    "        img = cv2.imread(os.path.join(input_path, filename))\n",
    "        height, width, channels = img.shape\n",
    "\n",
    "        # Data Augmentation\n",
    "        img_augmented = datagen.random_transform(img)\n",
    "        \n",
    "        # Convert to grayscale and apply CLAHE to the entire image\n",
    "        clahe = cv2.createCLAHE(clipLimit=3.0, tileGridSize=(8, 8))\n",
    "        gray_image = cv2.cvtColor(img_augmented, cv2.COLOR_BGR2GRAY)\n",
    "        clahe_image = clahe.apply(gray_image)\n",
    "        clahe_image = cv2.GaussianBlur(clahe_image, (3, 3), 0)\n",
    "        \n",
    "        # Face detection with a deep learning-based model (using SSD)\n",
    "        blob = blobFromImage(cv2.resize(img_augmented, (300, 300)), 1.0, (300, 300), (104.0, 177.0, 123.0))\n",
    "        face_net.setInput(blob)\n",
    "        detections = face_net.forward()\n",
    "\n",
    "        faces = []\n",
    "        for i in range(detections.shape[2]):\n",
    "            confidence = detections[0, 0, i, 2]\n",
    "            if confidence > 0.4:  # Lowered threshold\n",
    "                box = detections[0, 0, i, 3:7] * np.array([width, height, width, height])\n",
    "                (x, y, x1, y1) = box.astype(\"int\")\n",
    "                faces.append([x, y, x1 - x, y1 - y])\n",
    "\n",
    "        faces = non_max_suppression(faces, 0.3)\n",
    "        classification = classify_face(filename)\n",
    "        \n",
    "        if len(faces) == 0:\n",
    "            TN += (classification == 'not real')\n",
    "            FN += (classification == 'real')\n",
    "            y_true_faces.append(0)\n",
    "            y_pred_faces.append(0)\n",
    "        else:\n",
    "            for (x, y, w, h) in faces:\n",
    "                cv2.rectangle(img, (x, y), (x+w, y+h), (0, 0, 0), 2)\n",
    "                cv2.putText(img, classification, (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 0, 0), 2)\n",
    "                \n",
    "            TP += (classification == 'real')\n",
    "            FP += (classification == 'not real')\n",
    "            y_true_faces.append(1)\n",
    "            y_pred_faces.append(1)\n",
    "        \n",
    "        # Prepare image for YOLO object detection\n",
    "        blob = blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "        net.setInput(blob)\n",
    "        outs = net.forward(output_layers)\n",
    "        \n",
    "        # Get detection results\n",
    "        class_ids = []\n",
    "        confidences = []\n",
    "        boxes = []\n",
    "        for out in outs:\n",
    "            detection = out.reshape(-1, 85)\n",
    "            for obj in detection:\n",
    "                scores = obj[5:]\n",
    "                class_id = np.argmax(scores)\n",
    "                confidence = scores[class_id]\n",
    "                if confidence > 0.5:  # Lowered threshold\n",
    "                    center_x = int(obj[0] * width)\n",
    "                    center_y = int(obj[1] * height)\n",
    "                    w = int(obj[2] * width)\n",
    "                    h = int(obj[3] * height)\n",
    "                    x = int(center_x - w / 2)\n",
    "                    y = int(center_y - h / 2)\n",
    "                    boxes.append([x, y, w, h])\n",
    "                    confidences.append(float(confidence))\n",
    "                    class_ids.append(class_id)\n",
    "\n",
    "        # Apply Non-Max Suppression\n",
    "        indexes = NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
    "        \n",
    "        if len(indexes) > 0:\n",
    "            y_pred_objects.append(1)\n",
    "            for i in indexes.flatten():\n",
    "                x, y, w, h = boxes[i]\n",
    "                label = str(classes[class_ids[i]])\n",
    "                confidence = confidences[i]\n",
    "                color = (0, 255, 0)\n",
    "                cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
    "                cv2.putText(img, f\"{label} {int(confidence * 100)}%\", (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, color, 2)\n",
    "        else:\n",
    "            y_pred_objects.append(0)\n",
    "\n",
    "        # Update y_true_objects for object detection\n",
    "        true_label = classify_face(filename)\n",
    "        if true_label == 'real':\n",
    "            y_true_objects.append(1)\n",
    "        else:\n",
    "            y_true_objects.append(0)\n",
    "        \n",
    "        # Save the processed image\n",
    "        cv2.imwrite(os.path.join(output_path, filename), img)\n",
    "        print(f'Saved {filename} with classification {classification}')\n",
    "\n",
    "# Print debug information\n",
    "print(\"Length of y_true_faces:\", len(y_true_faces))\n",
    "print(\"Length of y_pred_faces:\", len(y_pred_faces))\n",
    "print(\"Length of y_true_objects:\", len(y_true_objects))\n",
    "print(\"Length of y_pred_objects:\", len(y_pred_objects))\n",
    "\n",
    "# Calculate performance metrics if lengths match\n",
    "if len(y_true_objects) == len(y_pred_objects):\n",
    "    total_images = TP + TN + FP + FN\n",
    "    print(f\"TP: {TP}, TN: {TN}, FP: {FP}, FN: {FN}\")\n",
    "    print(f\"Accuracy: {(TP + TN) / total_images * 100:.2f}%\")\n",
    "\n",
    "    # Confusion Matrix and Classification Report for Face Detection\n",
    "    conf_matrix_faces = confusion_matrix(y_true_faces, y_pred_faces)\n",
    "    print(\"Confusion Matrix for Faces:\\n\", conf_matrix_faces)\n",
    "    print(\"Classification Report for Faces:\\n\", classification_report(y_true_faces, y_pred_faces))\n",
    "\n",
    "    # Confusion Matrix and Classification Report for Object Detection\n",
    "    conf_matrix_objects = confusion_matrix(y_true_objects, y_pred_objects)\n",
    "    print(\"Confusion Matrix for Objects:\\n\", conf_matrix_objects)\n",
    "    print(\"Classification Report for Objects:\\n\", classification_report(y_true_objects, y_pred_objects))\n",
    "else:\n",
    "    print(\"Mismatch in the length of true and predicted\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
